{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hog\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from glob import glob\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from skimage.feature import hog\n",
    "\n",
    "import PIL\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_paths = glob(\"../input/the-car-connection-picture-dataset\"+\"/*\")[:5000]\n",
    "neg_paths = []\n",
    "\n",
    "for class_path in glob(\"../input/natural-images/natural_images\"+\"/*\"):\n",
    "    if class_path != \"../input/natural-images/natural_images/car\":\n",
    "        paths = random.choices(glob(class_path+\"/*\"),k=700)\n",
    "        neg_paths = paths + neg_paths\n",
    "        \n",
    "print(\"There are {} car images in the dataset\".format(len(car_paths)))\n",
    "print(\"There are {} negative images in the dataset\".format(len(neg_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(filename: str=None) -> None:\n",
    "    \"\"\"\n",
    "    View multiple images stored in files, stacking vertically\n",
    "\n",
    "    Arguments:\n",
    "        filename: str - path to filename containing image\n",
    "    \"\"\"\n",
    "    image = mpimg.imread(filename)\n",
    "    # <something gets done here>\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "\n",
    "for file in car_paths[:1]:\n",
    "    process(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in neg_paths[1020:1022]:\n",
    "    process(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = np.asarray(PIL.Image.open(car_paths[51]))\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "plt.imshow(example_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "hog_features, visualized = hog(image=example_image,\n",
    "                              orientations=9,\n",
    "                              pixels_per_cell=(16,16),\n",
    "                              cells_per_block=(2,2),\n",
    "                              visualize=True,\n",
    "                              multichannel=True)\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.imshow(example_image)\n",
    "plt.axis(\"off\")\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.imshow(visualized,cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_images = []\n",
    "neg_images = []\n",
    "\n",
    "pos_labels = np.ones(len(car_paths))\n",
    "neg_labels = np.zeros(len(neg_paths))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for car_path in car_paths:    \n",
    "    img = np.asarray(PIL.Image.open(car_path))\n",
    "    # We don't have to use RGB channels to extract features, Grayscale is enough.\n",
    "    img = cv2.cvtColor(cv2.resize(img,(96,64)),cv2.COLOR_RGB2GRAY)\n",
    "    img = hog(img,orientations=9,pixels_per_cell=(16,16),\n",
    "              cells_per_block=(2,2)\n",
    "             )\n",
    "    \n",
    "    pos_images.append(img)\n",
    "\n",
    "for neg_path in neg_paths:\n",
    "    img = np.asarray(PIL.Image.open(neg_path))\n",
    "    img = cv2.cvtColor(cv2.resize(img,(96,64)),cv2.COLOR_RGB2GRAY)\n",
    "    img = hog(img,orientations=9,pixels_per_cell=(16,16),\n",
    "              cells_per_block=(2,2)\n",
    "             )\n",
    "    \n",
    "    neg_images.append(img)\n",
    "    \n",
    "x = np.asarray(pos_images + neg_images)\n",
    "y = np.asarray(list(pos_labels) + list(neg_labels))\n",
    "    \n",
    "processTime = round(time.time()-start,2)\n",
    "print(\"Reading images and extracting features has taken {} seconds\".format(processTime))\n",
    "\n",
    "print(\"Shape of image set\",x.shape)\n",
    "print(\"Shape of labels\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Creating a SVC object\n",
    "svc = SVC(kernel = 'rbf', verbose=True, random_state=42)\n",
    "\n",
    "# Fit the training dataset\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "y_pred = svc.predict(x_test)\n",
    "print(\"Accuracy score of model is \",round(accuracy_score(y_pred=y_pred,y_true=y_test)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "def test_prediction(img_path, true_label, svc):\n",
    "    img = np.asarray(PIL.Image.open(img_path))\n",
    "    img_gray = cv2.cvtColor(cv2.resize(img,(96,64)),cv2.COLOR_RGB2GRAY)\n",
    "    image, viz = hog(img_gray,orientations=9,pixels_per_cell=(16,16),\n",
    "              cells_per_block=(2,2), visualize=True)\n",
    "        \n",
    "    x_tst = np.asarray(image)\n",
    "    pred = svc.predict([x_tst])\n",
    "    \n",
    "    print(\"True label: \", true_label)\n",
    "    plt.imshow(img)\n",
    "    if pred[0] == 0.0:\n",
    "        print(\"Prediction: Not car\")\n",
    "        \n",
    "    elif pred[0] == 1.0:\n",
    "        print(\"Prediction: Car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(neg_paths[2], \"Not car\", svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(car_paths[15], \"Car\", svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(car_paths[3], \"Car\", svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(neg_paths[-1], \"Not car\", svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a SVC object\n",
    "svc = SVC()\n",
    "svc1 = SVC(C=0.01)\n",
    "svc2 = SVC(C=100)\n",
    "\n",
    "# Fitting the parameters\n",
    "svc.fit(x_train,y_train)\n",
    "svc1.fit(x_train,y_train)\n",
    "svc2.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "y_pred = svc.predict(x_test)\n",
    "print(\"Accuracy score of svc model is \",round(accuracy_score(y_pred=y_pred,y_true=y_test)*100,2))\n",
    "\n",
    "y_pred = svc1.predict(x_test)\n",
    "print(\"Accuracy score of svc1 model with c=0.01 is \",round(accuracy_score(y_pred=y_pred,y_true=y_test)*100,2))\n",
    "\n",
    "y_pred = svc2.predict(x_test)\n",
    "print(\"Accuracy score of svc2 model with c=100 is \",round(accuracy_score(y_pred=y_pred,y_true=y_test)*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(neg_paths[-1], \"Not car\", svc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction(neg_paths[4000], \"Not car\", svc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(svc, x_test, y_test, cv=5)\n",
    "scores1 = cross_val_score(svc1, x_test, y_test, cv=5)\n",
    "scores2 = cross_val_score(svc2, x_test, y_test, cv=5)\n",
    "print(\"Accuracy for svc with c=1.0: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"Accuracy for svc with c=0.01: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))\n",
    "print(\"Accuracy for svc with c=100: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slideExtract(image,windowSize=(96,64),channel=\"RGB\",step=12):\n",
    "    \n",
    "    # Converting to grayscale\n",
    "    if channel == \"RGB\":\n",
    "        img = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    elif channel == \"BGR\":\n",
    "        img = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    elif channel.lower()!=\"grayscale\" or channel.lower()!=\"gray\":\n",
    "        raise Exception(\"Invalid channel type\")\n",
    "    \n",
    "    # We'll store coords and features in these lists\n",
    "    coords = []\n",
    "    features = []\n",
    "    \n",
    "    hIm,wIm = image.shape[:2] \n",
    "\n",
    "    \n",
    "    # W1 will start from 0 to end of image - window size\n",
    "    # W2 will start from window size to end of image\n",
    "    # We'll use step (stride) like convolution kernels.\n",
    "    for w1,w2 in zip(range(0,wIm-windowSize[0],step),range(windowSize[0],wIm,step)):\n",
    "       \n",
    "        for h1,h2 in zip(range(0,hIm-windowSize[1],step),range(windowSize[1],hIm,step)):\n",
    "            window = img[h1:h2,w1:w2]\n",
    "            features_of_window = hog(window,orientations=9,pixels_per_cell=(16,16),\n",
    "                                     cells_per_block=(2,2)\n",
    "                                    )\n",
    "            \n",
    "            coords.append((w1,w2,h1,h2))\n",
    "            features.append(features_of_window)\n",
    "    \n",
    "    return (coords,np.asarray(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = np.asarray(PIL.Image.open(\"../input/the-car-connection-picture-dataset/Acura_ILX_2013_28_16_110_15_4_70_55_179_39_FWD_5_4_4dr_Mro.jpg\"))\n",
    "coords,features = slideExtract(example_image,channel=\"RGB\")\n",
    "\n",
    "coords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class Heatmap():\n",
    "    \n",
    "    def __init__(self,original_image):\n",
    "        \n",
    "        # Mask attribute is the heatmap initialized with zeros\n",
    "        self.mask = np.zeros(original_image.shape[:2])\n",
    "    \n",
    "    # Increase value of region function will add some heat to heatmap\n",
    "    def incValOfReg(self,coords):\n",
    "        w1,w2,h1,h2 = coords\n",
    "        self.mask[h1:h2,w1:w2] = self.mask[h1:h2,w1:w2] + 30\n",
    "    \n",
    "    # Decrease value of region function will remove some heat from heatmap\n",
    "    # We'll use this function if a region considered negative\n",
    "    def decValOfReg(self,coords):\n",
    "        w1,w2,h1,h2 = coords\n",
    "        self.mask[h1:h2,w1:w2] = self.mask[h1:h2,w1:w2] - 30\n",
    "    \n",
    "    def compileHeatmap(self):\n",
    "        \n",
    "        # As you know,pixel values must be between 0 and 255 (uint8)\n",
    "        # Now we'll scale our values between 0 and 255 and convert it to uint8\n",
    "        \n",
    "        # Scaling between 0 and 1 \n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        self.mask = scaler.fit_transform(self.mask)\n",
    "        \n",
    "        \n",
    "        # Scaling between 0 and 255\n",
    "        self.mask = np.asarray(self.mask * 255).astype(np.uint8)\n",
    "        \n",
    "        # Now we'll threshold our mask, if a value is higher than 170, it will be white else\n",
    "        # it will be black\n",
    "        self.mask = cv2.inRange(self.mask,170,255)\n",
    "        \n",
    "        return self.mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_mask = np.zeros((200,200))\n",
    "example_mask[70:100,60:120] = 255\n",
    "\n",
    "plt.imshow(example_mask,cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours function of openCV will help us the find white regions.\n",
    "contours, hierarchy = cv2.findContours(example_mask.astype(np.uint8),1,2)[-2:]\n",
    "for c in contours:\n",
    "    if cv2.contourArea(c) < 10*10:\n",
    "        continue\n",
    "    (x,y,w,h) = cv2.boundingRect(c)\n",
    "    \n",
    "    rgb_ver = cv2.cvtColor(example_mask.astype(np.uint8),cv2.COLOR_GRAY2RGB)\n",
    "    im = cv2.rectangle(rgb_ver,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(image):\n",
    "    \n",
    "    # Extracting features and initalizing heatmap\n",
    "    coords,features = slideExtract(image)\n",
    "    htmp = Heatmap(image)\n",
    "    \n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        # If region is positive then add some heat\n",
    "        decision = svc.predict([features[i]])\n",
    "        if decision[0] == 1:\n",
    "            htmp.incValOfReg(coords[i])\n",
    "            # Else remove some heat\n",
    "        else:\n",
    "            htmp.decValOfReg(coords[i])\n",
    "    \n",
    "    # Compiling heatmap\n",
    "    mask = htmp.compileHeatmap()\n",
    "    \n",
    "    cont,_ = cv2.findContours(mask,1,2)[:2]\n",
    "    for c in cont:\n",
    "        # If a contour is small don't consider it\n",
    "        if cv2.contourArea(c) < 70*70:\n",
    "            continue\n",
    "        \n",
    "        (x,y,w,h) = cv2.boundingRect(c)\n",
    "        image = cv2.rectangle(image,(x,y),(x+w,y+h),(255),2)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected = detect(np.asarray(PIL.Image.open(\"../input/the-car-connection-picture-dataset/Acura_ILX_2013_28_16_110_15_4_70_55_179_39_FWD_5_4_4dr_ylA.jpg\")\n",
    "                            ))\n",
    "plt.imshow(detected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "\n",
    "byte_img = requests.get(\"https://images2.minutemediacdn.com/image/upload/c_crop,h_843,w_1500,x_0,y_69/f_auto,q_auto,w_1100/v1554995310/shape/mentalfloss/istock-472964014.jpg\").content\n",
    "byte_img = io.BytesIO(byte_img)\n",
    "\n",
    "img = np.asarray(PIL.Image.open(byte_img))\n",
    "\n",
    "detected = detect(img)\n",
    "plt.imshow(detected)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
